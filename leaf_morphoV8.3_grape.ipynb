{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze Grape Leaf Morhometrics - Goal: leaf area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import os\n",
    "import multiprocessing as mp\n",
    "import argparse\n",
    "import traceback\n",
    "import re\n",
    "# Third-party libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from pyzbar.pyzbar import decode\n",
    "from roboflow import Roboflow\n",
    "from inference_sdk import InferenceHTTPClient\n",
    "# Local application/library specific imports\n",
    "from plantcv import plantcv as pcv\n",
    "from plantcv.parallel import WorkflowInputs\n",
    "from qreader import QReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in size ref images\n",
    "ref1 = cv2.imread(\"/Volumes/silvas/SilvasLeafScans2024/Large tray size frame.tif\", cv2.IMREAD_COLOR)\n",
    "ref2 = cv2.imread(\"/Volumes/silvas/SilvasLeafScans2024/X-Large tray size frame.tif\", cv2.IMREAD_COLOR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the images using open cv - note: you will have to enter any key to close the images\n",
    "# any other method will crash the kernel\n",
    "cv2.imshow(\"ref1\", ref1)\n",
    "cv2.imshow(\"ref2\", ref2)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 1: Find the quarters in the image and calculate the average diameter\n",
    "### Goal: Divide pixels per dimeter by mm per quarter dia (24.26mm) to get pixels per mm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 1: Use Object detection using https://universe.roboflow.com/s1-sowiy/coins-l4wkp/model/7\n",
    "#### This method currently works succesfully"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLIENT = InferenceHTTPClient(\n",
    "    api_url=\"https://detect.roboflow.com\",\n",
    "    api_key=\"ifIr3Jg8nPSCOsbGEr86\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If image is too large, shrink it\n",
    "max_dimension = 2400\n",
    "height, width = ref1.shape[:2]\n",
    "if max(height, width) > max_dimension:\n",
    "    scaling_factor = max_dimension / float(max(height, width))\n",
    "    new_size = (int(width * scaling_factor), int(height * scaling_factor))\n",
    "    ref1 = cv2.resize(ref1, new_size, interpolation=cv2.INTER_AREA)\n",
    "else:\n",
    "   print(\"Image is small enough, no need to resize.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = CLIENT.infer(ref1, model_id=\"coins-l4wkp/7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = set()\n",
    "for prediction in result['predictions']:\n",
    "    classes.add(prediction['class'])\n",
    "\n",
    "# Convert the set to a list if needed\n",
    "classes_list = list(classes)\n",
    "print(\"Detected classes:\", classes_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref1_copy = ref1.copy()\n",
    "diameters = []\n",
    "# Iterate through the predictions to find the bounding box for the class \"Marker\"\n",
    "for prediction in result['predictions']:\n",
    "    x_center = int(prediction['x'])\n",
    "    y_center = int(prediction['y'])\n",
    "    diameter = int(max(prediction['width'], prediction['height']))\n",
    "    radius = diameter // 2\n",
    "    diameters.append(diameter)\n",
    "    \n",
    "    # Create a mask for the circle\n",
    "    mask = np.zeros(ref1_copy.shape[:2], dtype=np.uint8)\n",
    "    cv2.circle(mask, (x_center, y_center), radius, 255, -1)\n",
    "    \n",
    "    # Find the contours of the circle\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Draw the contours on the image\n",
    "    cv2.drawContours(ref1_copy, contours, -1, (0, 0, 0), 2)\n",
    "    radius = int(max(prediction['width'], prediction['height']) / 2)\n",
    "    \n",
    "    # Draw a black circle around the marker\n",
    "    cv2.circle(ref1_copy, (x_center, y_center), radius, (0, 255, 0), 2)\n",
    "\n",
    "cv2.imshow(\"ref1\", ref1_copy)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 2: Instance segmentation using https://universe.roboflow.com/ut-tyler-cmpe-3301/coin-detector-jcdoq/model/1\n",
    "#### I could not find an instance seg model that was public on roboflow for this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLIENT = InferenceHTTPClient(\n",
    "    api_url=\"https://detect.roboflow.com\",\n",
    "    api_key=\"ifIr3Jg8nPSCOsbGEr86\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = CLIENT.infer(ref1, model_id=\"coin-detector-jcdoq/1\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = set()\n",
    "for prediction in result['predictions']:\n",
    "    classes.add(prediction['class'])\n",
    "\n",
    "# Convert the set to a list if needed\n",
    "classes_list = list(classes)\n",
    "print(\"Detected classes:\", classes_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref1_copy = ref1.copy()\n",
    "for prediction in result['predictions']:\n",
    "    if prediction['class'] == 'Dime':\n",
    "        points = np.array([[p['x'], p['y']] for p in prediction['points']], dtype=np.int32).reshape((-1, 1, 2))\n",
    "\n",
    "        # Draw the polyline on the image (example image)\n",
    "        cv2.polylines(ref1, [points], isClosed=True, color=(0, 255, 0), thickness=2)\n",
    "\n",
    "cv2.imshow(\"ref1\", ref1)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 3, manual select pixels on ref1 and ref2 to get conversion factor\n",
    "#### I would suggest finding the pixels coordinates yourself and threshing color within that region"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Once avg quarter diameter in pixels is found use the following equation to create a conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note, dia is currently unassigned!\n",
    "pix_per_mm = dia/25.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in image to be analyzed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find file path name\n",
    "image_path = \"/Users/aja294/Documents/Grape_local/projects/leaf_morphometrics/images/05-08-24_LR_1-8_B.tif\"\n",
    "file_name = os.path.basename(image_path)\n",
    "file_name = os.path.splitext(file_name)[0]\n",
    "print(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in image on file path\n",
    "image = cv2.imread(image_path, cv2.IMREAD_COLOR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visually validate image, note image is in BGR, so colors will be inversed when printing in line wil plt.imshow\n",
    "plt.imshow(image)\n",
    "height, width = image.shape[:2]\n",
    "print(f\"Image dimensions: {width} x {height}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy a roboflow model to identify leaves, test one we already have on hand first\n",
    "### The first option is object detection (bounding boxes), the second is instance segmentation (smart polygons), test each "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Object detection, suggestion: create a sliding box for which to thresh images in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Object detection\n",
    "rf = Roboflow(api_key='l6XPyOniqM4Ecq129cpf')\n",
    "project = rf.workspace().project(\"grape_leaves\")\n",
    "model = project.version(\"1\").model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If image is too large, shrink it\n",
    "max_dimension = 2400\n",
    "height, width = image.shape[:2]\n",
    "if max(height, width) > max_dimension:\n",
    "    scaling_factor = max_dimension / float(max(height, width))\n",
    "    new_size = (int(width * scaling_factor), int(height * scaling_factor))\n",
    "    image = cv2.resize(image, new_size, interpolation=cv2.INTER_AREA)\n",
    "else:\n",
    "   print(\"Image is small enough, no need to resize.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.predict(image, confidence=40, overlap=30).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = set()\n",
    "for prediction in results['predictions']:\n",
    "    classes.add(prediction['class'])\n",
    "\n",
    "# Convert the set to a list if needed\n",
    "classes_list = list(classes)\n",
    "print(\"Detected classes:\", classes_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "for prediction in results['predictions']:\n",
    "    if prediction['class'] == 'Marker':\n",
    "        points = np.array([[p['x'], p['y']] for p in prediction['points']], dtype=np.int32).reshape((-1, 1, 2))\n",
    "\n",
    "        # Draw the polyline on the image (example image)\n",
    "        cv2.polylines(image, [points], isClosed=True, color=(0, 255, 0), thickness=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_copy = image.copy()\n",
    "for (x1, y1, x2, y2) in leaves:\n",
    "    # Apply mask\n",
    "    marker_region = image_copy[y1:y2, x1:x2]\n",
    "    # Further processing on marker_region\n",
    "    cv2.rectangle(image_copy, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "    cv2.putText(image_copy, 'leaf', (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "plt.imshow(image_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Option 2: Train an image segmention model to detect leaves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instance segmentation\n",
    "rf = Roboflow(api_key='l6XPyOniqM4Ecq129cpf')\n",
    "project = rf.workspace().project(\"morphometric_segmentation\")\n",
    "model = project.version(\"2\").model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = set()\n",
    "for prediction in results['predictions']:\n",
    "    classes.add(prediction['class'])\n",
    "\n",
    "# Convert the set to a list if needed\n",
    "classes_list = list(classes)\n",
    "print(\"Detected classes:\", classes_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_copy = image.copy()\n",
    "# print the outline of the leaf\n",
    "for prediction in results['predictions']:\n",
    "    if prediction['class'] == 'leaf':\n",
    "        points = np.array([[p['x'], p['y']] for p in prediction['points']], dtype=np.int32).reshape((-1, 1, 2))\n",
    "\n",
    "        # Draw the polyline on the image (example image)\n",
    "        cv2.polylines(image, [points], isClosed=True, color=(0, 255, 0), thickness=2)\n",
    "\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3, once a mask is created for each leaf, calculate mm2 and cm2 and print to a datasheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note leaf_area is undefined! Assign this value by finding pixels within a given leaf\n",
    "leaf_mm2 = leaf_area/pix_per_mm^2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "leaf_morpho-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
